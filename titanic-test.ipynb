{"cells":[{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'str' object has no attribute 'decode'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32m<ipython-input-2-0b99f5dec0bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'titanic.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"]}],"source":"#! /usr/bin/env python3\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport requests, json\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import preprocessing\n\ndata = pd.read_csv('titanic.csv', sep=',', low_memory=False)\n\ndata.dropna(inplace=True)\ndata.reset_index(drop=True, inplace=True)\n\nfeatures = data[['PassengerId','Pclass','Sex','Age','Embarked']]\ntarget = data['Survived']\n\nencoder = preprocessing.LabelEncoder()\nfor column in features:\n    if features[column].dtype == object:\n        features[column] = encoder.fit_transform(features[column])\n        \nX_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=0)\n\nmodel = RandomForestClassifier(n_estimators=10, random_state=0)  \nmodel.fit(X_train, y_train)  \nprob = model.predict(X_test)\nmodel.score(X_test, y_test)\n\nimport pickle \npickle.dump (model, open('modelRF.pkl', 'wb'))\n\n# local url \nurl = 'https://titanic-flask-app.herokuapp.com'\n\n# sample data \ndata = {'PassengerId':3,'Pclass':2,'Sex':1,'Age':17,'Embarked':2} \ndata = json.dumps (data)\n\nsend_request = requests.post(url, data)\nprint (send_request)\nprint (send_request.json())"},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":""}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}